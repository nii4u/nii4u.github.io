[{"authors":["Name \"Agnieszka Mikołajczyk\""],"categories":null,"content":"Info Agnieszka Mikołajczyk is a researcher at Gdańsk University of Technology. We work together in one team. Her research interests include machine learning, explainable AI, and image analysis.\nClick here to visit her website\n","date":1577836800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1577836800,"objectID":"5aa10bd16f5ba2891c67e0bf3813c024","permalink":"https://akwasigroch.github.io/authors/agnieszka-miko%C5%82ajczyk/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/agnieszka-miko%C5%82ajczyk/","section":"authors","summary":"Info Agnieszka Mikołajczyk is a researcher at Gdańsk University of Technology. We work together in one team. Her research interests include machine learning, explainable AI, and image analysis.\nClick here to visit her website","tags":null,"title":"Agnieszka Mikołajczyk","type":"authors"},{"authors":["admin"],"categories":null,"content":"I am an assistant researcher in the field of deep learning at the Gdańsk University of Technology. My research interests include deep learning algorithms in the field of computer vision. I conduct research on neural architecture search and skin lesion classification. I am also interested in self-supervised learning methods.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://akwasigroch.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an assistant researcher in the field of deep learning at the Gdańsk University of Technology. My research interests include deep learning algorithms in the field of computer vision. I conduct research on neural architecture search and skin lesion classification. I am also interested in self-supervised learning methods.","tags":null,"title":"Arkadiusz Kwasigroch","type":"authors"},{"authors":[],"categories":["Blog"],"content":"Introduction Recently, I have started to experiment with self-supervised learning techniques. In the last few months, we can see the rapid development of new methods. Moreover, self-supervised learning is reaching transfer learning performance.\nThis family of methods allows using of unlabeled data to increase the performance of the task (e.g. classification, detection or so on). To better understand the idea behind those algorithms visit here or here. Self-supervised learning is used not only in computer vision domain, here is an example of successful use of self-supervised learning in automatic speech recognition https://ai.facebook.com/blog/wav2vec-state-of-the-art-speech-recognition-through-self-supervision/\nIn this post, I focus on the paper Self-Supervised Learning of Pretext-Invariant Representations by Ishan Misra, Laurens van der Maaten from Facebook.\nIdea Self-supervised learning usually involves preparing a pretext task. For instance, apply rotation to the images, then train the network to predict the rotation angles. Thus, pretext task most often becomes a simple classification task. The advantage of this approach is that we do not need to have manually assigned labels. We can generate labels automatically. The pretext task training aims to obtain good quality image representations. So, after pretext task pretraining, we can train our network on a downstream task (our target task) using those representations. This approach is similar to transfer learning that also involves two stages – training on big dataset then training on a target task.\nIn the mentioned paper authors also perform data augmentation. However, they do not focus on the prediction of the properties of the transformation. Instead, they try to make the representation of the original image and a modified image similar. This makes sense. For example, the image of the dog should produce the same feature vector regardless of the rotation angle. This can lead to more robust computer vision algorithms.\n\r\r\rThese two images should produce similar representations\r\r\rHow to make the network produce the same representations? By proper design of the loss function. So the idea is to pass both the original image and modified image by the network. Then change the network parameters in the optimization process to make the representation of two images similar. It can be obtained by minimizing the distance between those two representations. Unfortunately, there is one problem. The network can learn the trivial solution, for example, return zeros for all examples. To avoid such solutions, the distance between the modified image and other images in the dataset should be maximized. This lead to the loss function of the following form:\n$$ h(\\mathbf v_{\\mathbf I}, \\mathbf v_{\\mathbf I^{t}}) = \\frac{\\exp( \\frac{s(\\mathbf v_{\\mathbf I}, \\mathbf v_{\\mathbf I^{t}})}{\\tau})}{\\exp( \\frac{s(\\mathbf v_{\\mathbf I}, \\mathbf v_{\\mathbf I^{t}})}{\\tau}) + \\sum_{I^{'} \\in \\mathcal{D}_{N}} \\exp( \\frac{s(\\mathbf v_{\\mathbf I^{t}}, \\mathbf v_{\\mathbf I^{'}})}{\\tau}) } $$\nA detailed explanation of the function is provided in the paper. The numerator is a distance between the image and its modification, while the denominator is a sum of distances between the modified image and other images in the dataset. What is important, this function is similar to the softmax function. Therefore, we can use the cross-entropy loss function available in deep learning libraries.\nYou can notice the representations of other images in the delimiter. Obtaining those every batch could be very costly, so the authors decided to construct a representation bank that contains representations of all images in the dataset. So instead of calculating that every time we can look up the array.\nThe authors made an extensive analysis of many tasks. I'm not going to describe this here. What is interesting, the authors managed to achieve better image detection performance using self-supervised learning instead transfer learning.\nImplementation I decided to implement the algorithm in the Pytorch library. The code is available here: https://github.com/akwasigroch/Pretext-Invariant-Representations. I performed initial experiments on the ISIC 2017 dataset. The dataset contains 2000 training images, 150 validation images, and 600 test images. I obtained the following results on ResNet50 network:\n 0.55 AUC - training from scratch (the network can't learn) 0.70 AUC - training using a self-supervised pre-trained network 0.80 AUC - training using transfer learning from a network trained on Imagenet dataset  I did not manage to reach the performance of transfer learning. However, the results are promising, and I think an increase in the number of images (I used the same images in supervised and self-supervised training) can lead to much better results. This is especially important in medical cases where many images are not labeled, as it is time-consuming and involves the work of a skilled medical specialist.\n","date":1583703489,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583703489,"objectID":"12e079663622f28cc9e4865646c53ca1","permalink":"https://akwasigroch.github.io/post/blog/pretext-invariant-representations/","publishdate":"2020-03-08T22:38:09+01:00","relpermalink":"/post/blog/pretext-invariant-representations/","section":"post","summary":"Introduction Recently, I have started to experiment with self-supervised learning techniques. In the last few months, we can see the rapid development of new methods. Moreover, self-supervised learning is reaching transfer learning performance.\nThis family of methods allows using of unlabeled data to increase the performance of the task (e.g. classification, detection or so on). To better understand the idea behind those algorithms visit here or here. Self-supervised learning is used not only in computer vision domain, here is an example of successful use of self-supervised learning in automatic speech recognition https://ai.","tags":[],"title":"Self-supervised learning with pretext invariant representations","type":"post"},{"authors":null,"categories":null,"content":"","date":1583690400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583690400,"objectID":"be2bba77f7b58be77da8158e5aea9446","permalink":"https://akwasigroch.github.io/talk/probabilistic_perspective/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/probabilistic_perspective/","section":"talk","summary":"The talk aims to describe and explain how variational autoencoders work. How to derive the loss function to perform training? Understanding of those concepts involves prior knowledge about probability and statistics. During the talk, I will introduce those concepts based on easier algorithms. I will begin from a very simple example of parameter estimation of Gaussian distribution. Then I will be introducing more and more complex theoretical principles relying on algorithms such as linear regression, logistic regression, and probabilistic PCA. This incremental gain of knowledge will finally lead to a better understanding of variational autoencoders as well as the use of probability theory in machine learning.","tags":[],"title":"Machine learning - probabilistic perspective","type":"talk"},{"authors":null,"categories":null,"content":"","date":1581357600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581357600,"objectID":"aa9cc001727667fa949dfb7aef421460","permalink":"https://akwasigroch.github.io/talk/selfsupervised_ml_gdansk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/selfsupervised_ml_gdansk/","section":"talk","summary":"The field of self-supervised learning is gaining more and more attention. This family of methods allows for unsupervised pretraining of neural networks that lead to better performance in the target tasks (classification, detection, etc). The skillful design of unsupervised task and loss function causes the network learning valuable features. During the talk, I will present the latest, efficient methods that lead to performance increase on many benchmark datasets","tags":[],"title":"Self-supervised learning in computer vision","type":"talk"},{"authors":[],"categories":["Blog"],"content":"I prepare a presentation on Variational Autoencoders to my university colleagues. I think what can help them understand the topic better. I noticed that a derivation of the loss function can cause problems as it requires understanding and intuition of probabilistic concepts.\nI think that understanding probabilistic PCA first helps to understand Variational Autoencoders faster. Probabilistic PCA is a great and simple algorithm. The big advantage of this algorithm is that all the probability distributions used in the algorithm are Gaussian distributions. So starting from the latent variable distribution $p(z)$ and distribution of observed variables conditioned on latent variable $p(x|z)$, we can easily obtain the distribution of observed variable $p(x)$, and posterior distribution $p(z|x)$. It could be obtained analytically by known equations. What's more, we can easily sample from that distribution using known libraries like Numpy or Scipy. So to gain the intuition for this algorithm, it is worth to play with the examples. From my experience, learning probabilistic PCA makes learning Variational Autoencoders much easier, because I started to \u0026ldquo;feel\u0026rdquo; the equations.\nI prepared the short implementation of the probabilistic PCA method. I plan to show the code to listeners on my presentation to make the algorithm easier to understand. I hope that it also helps you. The code is available at my Github:\nhttps://github.com/akwasigroch/probabilistic_pca\nI plan to prepare longer text on my blog concerning that method.\n","date":1580938689,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580938689,"objectID":"af30c0b3f7cc40c0aba6a2f5586a78d2","permalink":"https://akwasigroch.github.io/post/blog/probabilistic-pca/","publishdate":"2020-02-05T22:38:09+01:00","relpermalink":"/post/blog/probabilistic-pca/","section":"post","summary":"I prepare a presentation on Variational Autoencoders to my university colleagues. I think what can help them understand the topic better. I noticed that a derivation of the loss function can cause problems as it requires understanding and intuition of probabilistic concepts.\nI think that understanding probabilistic PCA first helps to understand Variational Autoencoders faster. Probabilistic PCA is a great and simple algorithm. The big advantage of this algorithm is that all the probability distributions used in the algorithm are Gaussian distributions.","tags":[],"title":"Learn probabilistic PCA first to better understand Variational Autoencoders","type":"post"},{"authors":null,"categories":["Courses"],"content":"The data science is a hot topic now, so together with Piotr Chlebek and CODE:ME foundation we decided to organize a data science course. The course took place on 11-12.01.2020 in Gdańsk. The number of participants was limited, and the list of participants was full long before the date of the course. This shows a huge interest in data science and machine learning. The participants represented different professions, so it was a very interesting experience to teach them. During the course, there were many interesting discussions, participants proposed interesting ideas about task solutions.\nThe scope of the course was very wide and the participants had an opportunity to learn the fundamentals of data science and machine learning, as well as the tools used in those areas. My part of the course includes the basics of data science tools and algorithms:\n Anaconda and Jupyter Numpy and Pandas Matplotlib and Seaborn Scikit-learn and Keras Classification, Regression, Clusterization Time series analysis Neural networks  The teaching materials was based on the data gathered from https://dane.gov.pl/. The page provides great datasets that are very useful to teach the basics of data preparation, visualization and so on. Moreover, the use of these data is much more fun! For example, this is much more interesting to predict the number of passengers in public transport in the home city than analyzing the iris dataset.\nAnother issue tackled by the participants was the analyze of football players from the FIFA game series. We were able to train the Support Vector Regression to predict the value of the players on the transfer market based on the rate of their skills like agility, strength etc. The obtained results were quite good. The problem was also validated on neural network, that performed even better.\n","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578960000,"objectID":"1371af39077575268465ab83abb68961","permalink":"https://akwasigroch.github.io/post/courses/first_edition/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/post/courses/first_edition/","section":"post","summary":"The data science is a hot topic now, so together with Piotr Chlebek and CODE:ME foundation we decided to organize a data science course. The course took place on 11-12.01.2020 in Gdańsk. The number of participants was limited, and the list of participants was full long before the date of the course. This shows a huge interest in data science and machine learning. The participants represented different professions, so it was a very interesting experience to teach them.","tags":null,"title":"Fundamentals of Data Science - Gdańsk","type":"post"},{"authors":["Arkadiusz Kwasigroch","Michał Grochowski","Agnieszka Mikołajczyk"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"e083017a836c8e34aa2ca713307098ce","permalink":"https://akwasigroch.github.io/publication/neural_architecture_search_ieee/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/neural_architecture_search_ieee/","section":"publication","summary":"Deep neural networks have achieved great success in many domains. However, successful deployment of such systems is determined by proper manual selection of the neural architecture. This is a tedious and time-consuming process that requires expert knowledge. Different tasks need very different architectures to obtain satisfactory results. The group of methods called the neural architecture search (NAS) helps to find effective architecture in an automated manner. In this paper, we present the use of an architecture search framework to solve the medical task of malignant melanoma detection. Unlike many other methods tested on benchmark datasets, we tested it on practical problem, which differs greatly in terms of difficulty in distinguishing between classes, resolution of images, data balance within the classes, and the number of data available. In order to find a suitable network structure, the hill-climbing search strategy was employed along with network morphism operations to explore the search space. The network morphism operations allow for incremental increases in the network size with the use of the previously trained network. This kind of knowledge reusing allows significantly reducing the computational cost. The proposed approach produces structures that achieve similar results to those provided by manually designed structures, at the same time making use of almost 20 times fewer parameters. What is more, the search process lasts on average only 18h on single GPU.","tags":null,"title":"Neural Architecture Search for Skin Lesion Classification","type":"publication"},{"authors":["Arkadiusz Kwasigroch","Michał Grochowski","Mateusz Mikołajczyk"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"16c8bb188a0694cb36ac0bc31dea09ea","permalink":"https://akwasigroch.github.io/publication/neural_architecture_search_mmar/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/neural_architecture_search_mmar/","section":"publication","summary":"The paper presents the results of the research on neural architecture search (NAS) algorithm. We utilized the hill climbing algorithm to search for well-performing structures of deep convolutional neural network. Moreover, we used the function preserving transformations which enabled the effective operation of the algorithm in a short period of time. The network obtained with the advantage of NAS was validated on skin lesion classification problem. We compared the parameters and performance of the automatically generated neural structure with the architectures selected manually, reported by the authors in previous papers. The obtained structure achieved comparable results to hand-designed networks, but with much fewer parameters then manually crafted architectures.","tags":null,"title":"Deep neural network architecture search using network morphism","type":"publication"},{"authors":["Michał Grochowski","Arkadiusz Kwasigroch","Agnieszka Mikołajczyk"],"categories":null,"content":"","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"b1ecc1daae83d2be610c1936fae12f82","permalink":"https://akwasigroch.github.io/publication/technical_issues/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/publication/technical_issues/","section":"publication","summary":"In recent years, deep learning and especially deep neural networks (DNN) have obtained amazing performance on a variety of problems, in particular in classification or pattern recognition. Among many kinds of DNNs, the convolutional neural networks (CNN) are most commonly used. However, due to their complexity, there are many problems related but not limited to optimizing network parameters, avoiding overfitting and ensuring good generalization abilities. Therefore, a number of methods have been proposed by the researchers to deal with these problems. In this paper, we present the results of applying different, recently developed methods to improve deep neural network training and operating. We decided to focus on the most popular CNN structures, namely on VGG based neural networks: VGG16, VGG11 and proposed by us VGG8. The tests were conducted on a real and very important problem of skin cancer detection. A publicly available dataset of skin lesions was used as a benchmark. We analyzed the influence of applying: dropout, batch normalization, model ensembling, and transfer learning. Moreover, the influence of the type of activation function was checked. In order to increase the objectivity of the results, each of the tested models was trained 6 times and their results were averaged. In addition, in order to mitigate the impact of the selection of learning, test and validation sets, k-fold validation was applied.","tags":null,"title":"Selected technical issues of deep neural networks for image classification purposes","type":"publication"},{"authors":["Michał Grochowski","Agnieszka Mikołajczyk","Arkadiusz Kwasigroch"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"7abde6b523c8d7573b5ded7d8acfb2d8","permalink":"https://akwasigroch.github.io/publication/diagnosis_of_malignant_melanoma/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/diagnosis_of_malignant_melanoma/","section":"publication","summary":"Malignant melanomas are the most deadly type of skin cancer, yet detected early have high chances of successful treatment. In the last twenty years, the interest in automatic recognition and classification of melanoma dynamically increased, partly because of appearing public datasets with dermatoscopic images of skin lesions. Automated computer-aided skin cancer detection in dermatoscopic images is a very challenging task due to uneven sizes of datasets, huge intra-class variation with small interclass variation, and the existence of many artifacts in the images. One of the most recognized methods of melanoma diagnosis is the ABCD method. In the paper, we propose an extended version of this method and an intelligent decision support system based on neural networks that uses its results in the form of hand-crafted features. Automatic determination of the skin features with the ABCD method is difficult due to the large diversity of images of various quality, the existence of hair, different markers and other obstacles. Therefore, it was necessary to apply advanced methods of pre-processing the images. The proposed system is an ensemble of ten neural networks working in parallel, and one network using their results to generate a final decision. This system structure enables to increase the efficiency of its operation by several percentage points compared with a single neural network. The proposed system is trained on over 5000 and tested afterwards on 200 skin moles. The presented system can be used as a decision support system for primary care physicians, as a system capable of self-examination of the skin with a dermatoscope and also as an important tool to improve biopsy decision making.","tags":null,"title":"Diagnosis of Malignant Melanoma by Neural Network Ensemble-Based System Utilising Hand-Crafted Skin Lesion Features","type":"publication"},{"authors":["Arkadiusz Kwasigroch","Bartłomiej Jarzembinski","Michał Grochowski"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"7bdb28172897d854b2c8ad8c27232eed","permalink":"https://akwasigroch.github.io/publication/diabetic_retinopathy/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/publication/diabetic_retinopathy/","section":"publication","summary":"The diabetic retinopathy is a disease caused by long-standing diabetes. Lack of effective treatment can lead to vision impairment and even irreversible blindness. The disease can be diagnosed by examining digital color fundus photographs of retina. In this paper we propose deep learning approach to automated diabetic retinopathy screening. Deep convolutional neural networks (CNN) - the most popular kind of deep learning algorithms - enjoyed great success in the field of image analysis and recognition. Therefore, we leverage CNN networks to diagnose the diabetic retinopathy and its current stage, based on analysis of the photographs of retina. The utilized models were trained using dataset containing over 88000 retina photographs, labeled by specialist clinicians. To enhance the performance of the system, we proposed a special class coding technique that enabled to include the information about value of difference between predicted score and target score into the objective function being minimized during the neural networks training. To evaluate classification ability of employed models we used standard accuracy metrics and quadratic weighted Kappa score that is calculated between the predicted scores and scores provided in the dataset. The best tested model achieved an accuracy of about 82% in detecting the retinopathy and 51% in assessing its stage. Moreover, system obtained decent Kappa score equal 0.776. Achieved results showed that deep learning algorithms can be successfully employed to solve this very hard to analyze problem.","tags":null,"title":"Deep CNN based decision support system for detection and assessing the stage of diabetic retinopathy","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8e7bc052bdfc6746ea2bb6595e8093eb","permalink":"https://akwasigroch.github.io/home/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]